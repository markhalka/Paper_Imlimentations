{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDBD.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1UqfiLmyQGZtQJ9qqLIUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markhalka/Paper_Imlimentations/blob/main/IDBD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0MM7zr3TZU3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\"\"\"\n",
        "Impliments the paper: Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta by Sutton et. al\n",
        "\n",
        "Incremental Delta Bar Delta is a type of meta-learning algorithm, which learns the best parameters for\n",
        "a stochastic gradient descent process (such as a neural network). It learns over time how best to adjust\n",
        "biases (in this case the learning rate), and it is escpecially well suited for non-stationary domains\n",
        "\"\"\"\n",
        "\n",
        "# define the default parameters used in the paper\n",
        "DEFAULT_WEIGHTS = 0.04\n",
        "DEFAULT_BETA = -3\n",
        "DEFAULT_LR = 0\n",
        "DEFAULT_THETA = 0.01 \n",
        "\n",
        "class Learner():\n",
        "    def __init__(self, input_size):\n",
        "        self.size = input_size\n",
        "        self.weights = [DEFAULT_WEIGHTS] * self.size\n",
        "        self.betas = [DEFAULT_BETA] * self.size\n",
        "        self.h = np.zeros(self.size)\n",
        "        self.lrs = [DEFAULT_LR] * self.size\n",
        "        self.theta = DEFAULT_THETA\n",
        "        for i in range(self.size):\n",
        "            self.lrs[i] = np.exp(self.betas[i])\n",
        "    \n",
        "    def get_delta(self, input, label):\n",
        "        if len(input) != self.size:\n",
        "            raise RuntimeError(\"incorrect input\")\n",
        "        y_hat = 0.0\n",
        "        for i in range(self.size):\n",
        "            y_hat += input[i] * self.weights[i]    \n",
        "        return label - y_hat\n",
        "     \n",
        "    def update_betas(self, delta, input):\n",
        "        for i in range(self.size):\n",
        "            self.betas[i] += delta * self.theta * self.h[i] * input[i]\n",
        "\n",
        "    def update_lrs(self, delta, input):\n",
        "        self.update_betas(delta, input)\n",
        "        for i in range(self.size):\n",
        "            self.lrs[i] = np.exp(self.betas[i])\n",
        "\n",
        "    def update_h(self, delta, input):\n",
        "        for i in range(self.size):\n",
        "            self.h[i] = self.h[i] * max(1-self.lrs[i] * pow(input[i],2), 0) + self.lrs[i] * delta * input[i]\n",
        "\n",
        "    def update_weights(self, input, label):\n",
        "        delta = self.get_delta(input, label)\n",
        "        self.update_lrs(delta, input)\n",
        "        self.update_h(delta, input)\n",
        "        for i in range(self.size):\n",
        "            self.weights[i] += self.lrs[i] * delta * input[i]\n",
        "        return delta\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Impliment the same tests as in the paper, and compare results\n",
        "The test is a simple non-stationary task, for more information, consult the paper\n",
        "\"\"\"\n",
        "class Tests():\n",
        "    def __init__(self):\n",
        "        self.weights = [1] * 5\n",
        "        self.count = 0\n",
        "        self.learner = Learner(20)\n",
        "        \n",
        "    def get_data(self, n):\n",
        "        if n < 5:\n",
        "            raise RuntimeError(\"must be at least 5\")\n",
        "        vec =  np.random.normal(size=n)\n",
        "        label = np.sum(vec[0:5] * self.weights)\n",
        "        return vec, label\n",
        "    \n",
        "    def change_weights(self):\n",
        "        index = np.random.randint(0,5)\n",
        "        self.weights[index] *= -1\n",
        "\n",
        "    def get_next(self):\n",
        "        self.count += 1\n",
        "        if self.count % 20 == 0:\n",
        "            self.change_weights()\n",
        "        return self.get_data(20)\n",
        "\n",
        "    def run_test(self):\n",
        "        error = 0.0\n",
        "        for i in range(20000):\n",
        "            input, label = self.get_next()\n",
        "            delta = pow(self.learner.update_weights(input, label),2)\n",
        "            error += 1/1000 * delta\n",
        "            if i % 1000 == 0:\n",
        "                print(\"avg mse: %f\" % (error))\n",
        "                error = 0\n",
        "\n",
        "test = Tests()\n",
        "test.run_test()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}